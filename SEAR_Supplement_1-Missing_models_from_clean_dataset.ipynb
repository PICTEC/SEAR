{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the entry point to launch experiments from 2019 revision\n",
    "\n",
    "\n",
    "Launching this script will set up a single machine task queue and schedule all experiments to run on the machine. The experiments may take some time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:265: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bernoulli.py:169: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from sear_lib import DatasetPreparation, Training, Evaluation, ModelSchema, SlackNotifications\n",
    "from model_list import get_schema\n",
    "\n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "class State:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, \"rb\") as f:\n",
    "                self.dict = pickle.load(f)\n",
    "        else:\n",
    "            self.dict = {}\n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        return self.dict[k]\n",
    "    \n",
    "    def __setitem__(self, k, v):\n",
    "        self.dict[k] = v\n",
    "        with open(self.path, \"wb\") as f:\n",
    "            pickle.dump(self.dict, f)\n",
    "\n",
    "    def get(self, k):\n",
    "        return self.dict.get(k)\n",
    "    \n",
    "state = State(\".state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function model_list.mk_conv_dense.<locals>.mk_model(**kwargs)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_schema(\"conv_dense\", \"full_separate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None-amr-lq-dense-full_separate-supplement has been already run: {'name': 'model_2019-04-25T14:06:24.551510.zip', 'MSE': array([1.7190913, 1.6318938, 1.6404318, 1.5899776, 1.7824   , 1.5474149,\n",
      "       1.7634413, 2.2833476, 1.6370338, 1.7052227, 1.5028586, 1.6647881,\n",
      "       2.5920265, 2.0177908, 1.6175104, 1.6360805, 1.7029454, 1.8010554,\n",
      "       1.9364871, 2.2549746, 1.2502592, 1.0170828, 1.723542 , 1.6914687,\n",
      "       1.7549074, 1.685565 , 1.5625029, 1.7645342, 1.7444279, 1.6762348,\n",
      "       1.735394 , 1.6828679, 1.7597034, 1.8444793, 1.8342761, 1.7539115,\n",
      "       1.3386745, 1.6986583, 1.5252372, 2.0059304, 1.891033 , 2.0759165,\n",
      "       2.075795 , 1.7141712, 1.6465513, 1.7100344, 1.6757346, 1.5445809,\n",
      "       1.4942515, 1.6767954, 1.6819978, 1.6025441, 1.8965199, 1.9729441,\n",
      "       1.7912726, 1.7038544, 1.6673445, 1.8404953, 2.0404503, 1.6358534,\n",
      "       1.8160094, 1.6287231, 2.4818983, 1.9667954, 1.8367399, 1.730155 ,\n",
      "       1.4885278, 1.777102 , 1.6092793, 1.6641997, 1.6599752, 1.6148546,\n",
      "       1.5875183, 1.8423699, 1.7054982, 1.6487929, 1.702596 , 1.8675555,\n",
      "       1.5976794, 1.717536 ], dtype=float32), 'MAE': array([1.3149332 , 1.2270571 , 1.1655502 , 1.1956697 , 1.3581901 ,\n",
      "       1.1940204 , 1.2999442 , 1.7037867 , 1.267957  , 1.2519203 ,\n",
      "       1.0222329 , 1.2171062 , 1.9545734 , 1.4972554 , 1.244775  ,\n",
      "       1.0451056 , 1.3084399 , 1.3504542 , 1.4982338 , 1.6731862 ,\n",
      "       0.7369592 , 0.4576157 , 1.1986217 , 1.2399186 , 1.2973886 ,\n",
      "       1.27431   , 1.19905   , 1.3262429 , 1.3057921 , 1.2909253 ,\n",
      "       1.315194  , 1.2967951 , 1.287086  , 1.2805196 , 1.4036001 ,\n",
      "       1.3446486 , 0.63360107, 1.3088818 , 1.0420344 , 1.4884007 ,\n",
      "       1.4398321 , 1.5638031 , 1.554357  , 1.2992089 , 1.2175156 ,\n",
      "       1.3004754 , 1.2887977 , 1.1901103 , 0.693694  , 1.2680606 ,\n",
      "       1.2846546 , 1.2109003 , 1.37732   , 1.4635428 , 1.344135  ,\n",
      "       1.3051444 , 1.2753646 , 1.395036  , 1.5592282 , 1.2425083 ,\n",
      "       1.3733363 , 1.2425817 , 1.8470405 , 1.3827286 , 1.4086537 ,\n",
      "       1.2945569 , 1.0772648 , 1.3578905 , 1.2311081 , 1.2761736 ,\n",
      "       1.2759047 , 1.229628  , 1.2179605 , 1.4108212 , 1.3123442 ,\n",
      "       1.2360629 , 1.2754136 , 1.4105656 , 1.1561445 , 1.3196918 ],\n",
      "      dtype=float32), 'PESQ': array([2.129, 2.84 , 2.549, 2.524, 2.581, 3.144, 1.602, 1.467, 2.392,\n",
      "       2.752, 2.783, 2.79 , 2.756, 2.631, 2.844, 3.295, 2.746, 2.467,\n",
      "       2.678, 2.115, 3.416, 2.071, 2.927, 2.146, 3.135, 1.956, 2.674,\n",
      "       2.045, 1.32 , 2.136, 2.558, 2.795, 2.41 , 2.501, 3.113, 2.629,\n",
      "       1.76 , 1.367, 2.534, 1.679, 2.494, 2.075, 2.071, 2.488, 2.808,\n",
      "       2.948, 2.998, 2.492, 1.579, 2.199, 3.094, 3.169, 2.279, 2.073,\n",
      "       2.767, 1.317, 2.802, 2.834, 2.055, 1.576, 2.78 , 3.001, 2.82 ,\n",
      "       2.688, 2.507, 2.448, 2.051, 2.883, 2.3  , 2.146, 3.08 , 2.876,\n",
      "       2.652, 2.367, 2.3  , 2.72 , 2.511, 2.523, 3.143, 2.565]), 'LSD': array([ 6.7753592 ,  6.37834921,  5.91516524, ...,  7.2865197 ,\n",
      "       11.28790756, 11.17258022])}\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_lf (InputLayer)           (None, None, 129)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 129)    0           input_lf[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 129, 1) 0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, 129, 10 60          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, 129, 10 60          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, 129, 10 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, 129, 10 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, 129, 12 1092        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, 129, 12 1092        leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, 129, 12 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, 129, 12 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, 129, 14 854         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, 129, 14 854         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, 129, 14 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, 129, 14 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, 129, 16 2032        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, 129, 16 2032        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, 129, 16 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, 129, 16 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, 129, 18 1458        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, 129, 18 1458        leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, 129, 18 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, 129, 18 0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, 129, 20 3260        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, 129, 20 3260        leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, 129, 20 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, 129, 20 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, 129, 22 2222        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, 129, 22 2222        leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, 129, 22 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, 129, 22 0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, 129, 24 4776        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, 129, 24 4776        leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, 129, 24 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, 129, 24 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, 129, 1) 25          leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, 129, 1) 25          leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, 129, 1) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, 129, 1) 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, 129, 24 240         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, 129, 24 240         leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, 129, 24 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, 129, 24 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, 129, 22 2662        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, 129, 22 2662        leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, 129, 22 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, 129, 22 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, 129, 20 3980        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, 129, 20 3980        leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, 129, 20 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, None, 129, 20 0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, 129, 18 1818        leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, 129, 18 1818        leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, 129, 18 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, None, 129, 18 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, 129, 16 2608        leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, 129, 16 2608        leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, 129, 16 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, None, 129, 16 0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, 129, 14 1134        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, 129, 14 1134        leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, 129, 14 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, None, 129, 14 0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, 129, 12 1524        leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, 129, 12 1524        leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, 129, 12 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, None, 129, 12 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, 129, 10 610         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, 129, 10 610         leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, 129, 10 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, None, 129, 10 0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 1290)   0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 1290)   0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 129)    166539      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 128)    165248      time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 257)    0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 257)    0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 392,497\n",
      "Trainable params: 392,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 18.3398 - val_loss: 4.9759\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 673s 75ms/step - loss: 4.6948 - val_loss: 3.9986\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 672s 75ms/step - loss: 4.2229 - val_loss: 3.8983\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 673s 75ms/step - loss: 3.9010 - val_loss: 3.5158\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.7354 - val_loss: 3.4189\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.6580 - val_loss: 3.6076\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.5908 - val_loss: 3.3223\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.5490 - val_loss: 3.3342\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.4957 - val_loss: 3.3852\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.5014 - val_loss: 3.3257\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.4845 - val_loss: 3.2990\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 674s 75ms/step - loss: 3.4648 - val_loss: 3.2785\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.4127 - val_loss: 3.4824\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.4357 - val_loss: 3.2309\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.3987 - val_loss: 3.1689\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.3835 - val_loss: 3.1824\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.3622 - val_loss: 3.1829\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.3545 - val_loss: 3.1633\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.3386 - val_loss: 3.1407\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 675s 75ms/step - loss: 3.3442 - val_loss: 3.1387\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.3211 - val_loss: 3.1094\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.3073 - val_loss: 3.1112\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.2901 - val_loss: 3.0949\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.2659 - val_loss: 3.1004\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.2615 - val_loss: 3.1161\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.2475 - val_loss: 3.1432\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.2292 - val_loss: 3.1042\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 676s 75ms/step - loss: 3.2269 - val_loss: 3.2529\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.1582 - val_loss: 3.0272\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.1509 - val_loss: 3.0174\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.1480 - val_loss: 3.0055\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.1396 - val_loss: 3.0180\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.1315 - val_loss: 3.0683\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.1300 - val_loss: 3.0117\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.1243 - val_loss: 3.0112\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.1208 - val_loss: 3.0168\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 680s 76ms/step - loss: 3.0966 - val_loss: 2.9851\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0931 - val_loss: 2.9886\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0912 - val_loss: 2.9704\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0910 - val_loss: 2.9775\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0892 - val_loss: 2.9784\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0879 - val_loss: 2.9688\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0880 - val_loss: 2.9752\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0870 - val_loss: 2.9875\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0834 - val_loss: 2.9770\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0864 - val_loss: 2.9665\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0848 - val_loss: 2.9743\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0829 - val_loss: 2.9694\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0801 - val_loss: 2.9599\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0812 - val_loss: 2.9707\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0788 - val_loss: 2.9869\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0786 - val_loss: 2.9672\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0773 - val_loss: 2.9645\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0771 - val_loss: 2.9584\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0744 - val_loss: 2.9996\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0754 - val_loss: 2.9599\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0718 - val_loss: 2.9524\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0737 - val_loss: 2.9579\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0722 - val_loss: 2.9651\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0716 - val_loss: 2.9651\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0700 - val_loss: 2.9606\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0696 - val_loss: 2.9596\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0615 - val_loss: 2.9517\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0601 - val_loss: 2.9515\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0596 - val_loss: 2.9655\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0592 - val_loss: 2.9521\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0590 - val_loss: 2.9532\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0584 - val_loss: 2.9479\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0587 - val_loss: 2.9489\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0586 - val_loss: 2.9511\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0579 - val_loss: 2.9483\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0578 - val_loss: 2.9451\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0576 - val_loss: 2.9489\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 678s 75ms/step - loss: 3.0570 - val_loss: 2.9473\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0568 - val_loss: 2.9483\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0569 - val_loss: 2.9529\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 677s 75ms/step - loss: 3.0560 - val_loss: 2.9506\n",
      "<ZipInfo filename='model.h5' compress_type=deflate filemode='-rw-r--r--' file_size=4986176 compress_size=4343637>\n",
      "<ZipInfo filename='meta.pkl' compress_type=deflate filemode='-rw-r--r--' file_size=199 compress_size=173>\n",
      "Model path:  /home/zantyr/Denoising/runs/model_2019-04-29T16:33:27.679110.zip\n",
      "Model name: model_2019-04-29T16:33:27.679110.zip, MSE: 1.768456220626831 +- 0.2245609164237976, MAE: 1.3088735342025757 +- 0.21430087089538574, PESQ: 2.5526375 +- 0.5196928959431233, LSD: 7.538876311596354 +- 2.0998197049706535\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_lf (InputLayer)           (None, None, 129)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 129)    0           input_lf[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 129, 1) 0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, 129, 10 60          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, 129, 10 60          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, 129, 10 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, 129, 10 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, 129, 12 1092        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, 129, 12 1092        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, 129, 12 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, 129, 12 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, 129, 14 854         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, 129, 14 854         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, 129, 14 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, 129, 14 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, 129, 16 2032        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, 129, 16 2032        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, 129, 16 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, 129, 16 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 2064)   0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 2064)   0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 512)    1057280     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 512)    1057280     time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, 512)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, 512)    0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 96)     49248       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 96)     49248       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, 96)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, 96)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 512)    49664       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 512)    49664       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, 512)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, 512)    0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 512)    262656      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 512)    262656      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, 512)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, 512)    0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 129)    66177       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 128)    65664       leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 257)    0           dense_5[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 257)    0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,977,613\n",
      "Trainable params: 2,977,613\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 8.4228 - val_loss: 3.9795\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.9745 - val_loss: 3.5271\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.6851 - val_loss: 3.3024\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.4632 - val_loss: 3.3252\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.3309 - val_loss: 3.0733\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.2770 - val_loss: 3.0005\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.2142 - val_loss: 2.9960\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.1494 - val_loss: 3.0186\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 3.1389 - val_loss: 2.9955\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 3.0980 - val_loss: 2.9679\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 3.0638 - val_loss: 2.8960\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 3.0444 - val_loss: 2.8867\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 3.0123 - val_loss: 2.8888\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.9975 - val_loss: 2.8031\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.9698 - val_loss: 2.9035\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.9543 - val_loss: 2.8027\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.9359 - val_loss: 2.8781\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.9137 - val_loss: 2.8575\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.9090 - val_loss: 2.7777\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8940 - val_loss: 2.7925\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8773 - val_loss: 2.8155\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8579 - val_loss: 2.7745\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8528 - val_loss: 2.8119\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8367 - val_loss: 2.7065\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8283 - val_loss: 2.8882\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8165 - val_loss: 2.8351\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8111 - val_loss: 2.7177\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.8020 - val_loss: 2.7238\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7902 - val_loss: 2.6872\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7782 - val_loss: 2.7174\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7689 - val_loss: 2.7152\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7593 - val_loss: 2.6813\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7606 - val_loss: 2.7302\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 2.7452 - val_loss: 2.6708\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7351 - val_loss: 2.6772\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7268 - val_loss: 2.6571\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7206 - val_loss: 2.6490\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7184 - val_loss: 2.6653\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.7028 - val_loss: 2.6625\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6949 - val_loss: 2.6791\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6866 - val_loss: 2.6557\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6851 - val_loss: 2.6594\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6189 - val_loss: 2.6322\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6139 - val_loss: 2.6206\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6072 - val_loss: 2.6404\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6054 - val_loss: 2.6218\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.6009 - val_loss: 2.6240\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5965 - val_loss: 2.6398\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5938 - val_loss: 2.6157\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5919 - val_loss: 2.6413\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5879 - val_loss: 2.6347\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5832 - val_loss: 2.6220\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5776 - val_loss: 2.6475\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 2.5764 - val_loss: 2.6269\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 2.5504 - val_loss: 2.6153\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5483 - val_loss: 2.6134\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 2.5464 - val_loss: 2.6157\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 2.5449 - val_loss: 2.6348\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 2.5436 - val_loss: 2.6304\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 2.5428 - val_loss: 2.6230\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 2.5418 - val_loss: 2.6186\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5329 - val_loss: 2.6152\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5321 - val_loss: 2.6235\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5318 - val_loss: 2.6216\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5313 - val_loss: 2.6155\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5305 - val_loss: 2.6159\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 2.5302 - val_loss: 2.6176\n",
      "<ZipInfo filename='model.h5' compress_type=deflate filemode='-rw-r--r--' file_size=35878504 compress_size=33366158>\n",
      "<ZipInfo filename='meta.pkl' compress_type=deflate filemode='-rw-r--r--' file_size=199 compress_size=173>\n",
      "Model path:  /home/zantyr/Denoising/runs/model_2019-04-30T07:04:49.491253.zip\n",
      "Model name: model_2019-04-30T07:04:49.491253.zip, MSE: 1.671961784362793 +- 0.20014195144176483, MAE: 1.2301877737045288 +- 0.20125028491020203, PESQ: 2.69315 +- 0.5366256632886653, LSD: 7.105626508286753 +- 1.6827345267976652\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_lf (InputLayer)           (None, None, 129)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 129)    0           input_lf[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 129, 1) 0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, 129, 10 60          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, 129, 10 60          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, 129, 10 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, 129, 10 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, 129, 12 1092        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, 129, 12 1092        leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, 129, 12 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, 129, 12 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, 129, 14 854         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, 129, 14 854         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, 129, 14 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, 129, 14 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, 129, 16 2032        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, 129, 16 2032        leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, 129, 16 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, 129, 16 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, 129, 18 1458        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, 129, 18 1458        leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, 129, 18 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, 129, 18 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, 129, 20 3260        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, 129, 20 3260        leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, 129, 20 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, 129, 20 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, 129, 22 2222        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, 129, 22 2222        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, 129, 22 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, 129, 22 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, 129, 24 4776        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, 129, 24 4776        leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, 129, 24 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, 129, 24 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 3096)   0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 3096)   0           leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 512)    1585664     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 512)    1585664     time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, 512)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, 512)    0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 96)     49248       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 96)     49248       leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, 96)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, 96)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 512)    49664       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 512)    49664       leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, 512)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, 512)    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 512)    262656      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, None, 512)    262656      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, 512)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, 512)    0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 512)    262656      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, None, 512)    262656      leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, 512)    0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, 512)    0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 512)    262656      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, None, 512)    262656      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, 512)    0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, 512)    0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 129)    66177       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, None, 128)    65664       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 257)    0           dense_7[0][0]                    \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 257)    0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,108,437\n",
      "Trainable params: 5,108,437\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 393s 44ms/step - loss: 9.4554 - val_loss: 4.0828\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 393s 44ms/step - loss: 4.0817 - val_loss: 3.5919\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 394s 44ms/step - loss: 3.8500 - val_loss: 4.8909\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 394s 44ms/step - loss: 3.6673 - val_loss: 3.4977\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 395s 44ms/step - loss: 3.4546 - val_loss: 3.1239\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 395s 44ms/step - loss: 3.3245 - val_loss: 3.5578\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 395s 44ms/step - loss: 3.2261 - val_loss: 2.9696\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 3.1436 - val_loss: 2.9815\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 3.0875 - val_loss: 3.1117\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 3.0432 - val_loss: 3.1539\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 3.0046 - val_loss: 2.7887\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.9730 - val_loss: 2.9306\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.9581 - val_loss: 2.7932\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.9190 - val_loss: 3.0458\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.9012 - val_loss: 2.7688\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.8721 - val_loss: 2.8059\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.8504 - val_loss: 2.7361\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.8239 - val_loss: 2.7773\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.8213 - val_loss: 2.7207\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.8033 - val_loss: 2.7144\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.7871 - val_loss: 2.8032\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.7631 - val_loss: 2.6865\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.7449 - val_loss: 2.7480\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.7320 - val_loss: 2.6461\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.7259 - val_loss: 2.7156\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.7067 - val_loss: 2.6982\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6867 - val_loss: 2.6731\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6796 - val_loss: 2.6267\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6658 - val_loss: 2.6724\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6476 - val_loss: 2.6163\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6364 - val_loss: 2.6291\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6222 - val_loss: 2.5945\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.6112 - val_loss: 2.7255\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.5964 - val_loss: 2.5992\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.5789 - val_loss: 2.6565\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.5725 - val_loss: 2.6113\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 396s 44ms/step - loss: 2.5616 - val_loss: 2.6095\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.4821 - val_loss: 2.5917\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.4710 - val_loss: 2.5689\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.4616 - val_loss: 2.6024\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.4546 - val_loss: 2.5846\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.4493 - val_loss: 2.5804\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 398s 44ms/step - loss: 2.4449 - val_loss: 2.5849\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 397s 44ms/step - loss: 2.4355 - val_loss: 2.6033\n",
      "Train on 9000 samples, validate on 80 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 398s 44ms/step - loss: 2.4040 - val_loss: 2.5761\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 398s 44ms/step - loss: 2.4002 - val_loss: 2.5817\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 398s 44ms/step - loss: 2.3976 - val_loss: 2.5817\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 398s 44ms/step - loss: 2.3953 - val_loss: 2.5904\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 398s 44ms/step - loss: 2.3931 - val_loss: 2.5876\n",
      "Epoch 6/100\n",
      " 584/9000 [>.............................] - ETA: 6:10 - loss: 2.3889"
     ]
    }
   ],
   "source": [
    "codecs = [\"amr-lq\", \"amr-hq\", \"gsm-fr\"]\n",
    "noise_snr = [None]\n",
    "\n",
    "models = {\n",
    "    \"amr-lq\": [(\"dense\", \"full_separate\"), (\"dae\", \"full_separate\"),\n",
    "               (\"conv_dense\", \"full_separate\"), (\"conv_dense_4\", \"full_separate\"),\n",
    "               (\"dae_4\", \"full_separate\")],\n",
    "    \"amr-hq\": [(\"dae\", \"full_whole\"), (\"dae\", \"full_separate\")],\n",
    "    \"gsm-fr\": [(\"dense\", \"full_separate\"), (\"dae\", \"full_separate\"),\n",
    "               (\"conv_dense\", \"full_separate\"), (\"conv_dense_4\", \"full_separate\"),\n",
    "               (\"dae_4\", \"full_separate\")]\n",
    "}\n",
    "\n",
    "sn = SlackNotifications(\"https://hooks.slack.com/services/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\")\n",
    "\n",
    "for config in [DatasetPreparation.setting_for(codec, snr) for codec in codecs for snr in noise_snr]:\n",
    "    if state.get(f\"{config.SNR}-{config.codec_type}-supplement\") is None:\n",
    "        config.run()\n",
    "        state[f\"{config.SNR}-{config.codec_type}-supplement\"] = True\n",
    "    for model_type, variant in models[config.codec_type]:\n",
    "        key = f\"{config.SNR}-{config.codec_type}-{model_type}-{variant}-supplement\"\n",
    "        gettable = state.get(key)\n",
    "        if gettable is None:\n",
    "            train_task = Training(ModelSchema(get_schema(model_type, variant)), notifier=sn)\n",
    "            model = train_task.run()\n",
    "            eval_task = Evaluation(model)\n",
    "            evaluation = eval_task.run()\n",
    "            state[key] = evaluation\n",
    "        else:\n",
    "            print(f\"{key} has been already run: {state[key]}\")\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525813885.8\t    1535384566.2772486\t1537892524.121753\r\n",
      "1525815070.85\t    1535407939.7217238\t1537894521.1604176\r\n",
      "1525851363.52\t    1535408682.102181\t1537902074.7861135\r\n",
      "1525853811.6\t    1535412012.3308601\t1537902699.8369615\r\n",
      "1526289849.82\t    1535447086.151523\t1537905135.8774328\r\n",
      "1526290013.8\t    1535448418.8593493\t1537910170.17587\r\n",
      "1526290108.98\t    1535448495.842334\t1537913255.0667996\r\n",
      "1526293306.91\t    1535448751.162119\t1537952775.124493\r\n",
      "1526293363.72\t    1535449191.54567\t1537953701.9187071\r\n",
      "1526293625.29\t    1535449355.197668\t1537953789.9548697\r\n",
      "1526293831.87\t    1535450156.1960478\t1537958178.989777\r\n",
      "1526293933.85\t    1535453782.6359818\t1537977230.8142362\r\n",
      "1526294025.31\t    1535456892.4379327\t1537984291.910079\r\n",
      "1526294178.85\t    1535456975.6997151\t1537987934.4006574\r\n",
      "1526294328.68\t    1535457004.4943612\t1537993876.7080653\r\n",
      "1526294412.63\t    1535457067.1152833\t1538007073.2669153\r\n",
      "1526294508.69\t    1535460288.1290417\t1538013351.625412\r\n",
      "1526294694.73\t    1535462611.6018083\t1538067002.4245968\r\n",
      "1526295079.69\t    1535462808.6289124\t1538067691.4620302\r\n",
      "1526295232.48\t    1535462994.4063857\t1538067916.130728\r\n",
      "1526295404.39\t    1535463419.7669287\t1538068289.8006778\r\n",
      "1526295553.51\t    1535463466.1695564\t1538069047.5949426\r\n",
      "1526295813.4\t    1535463493.8353722\t1538070100.3270035\r\n",
      "1526463292.99\t    1535463645.7893898\t1538128409.288932\r\n",
      "1526463412.0\t    1535465830.4307501\t1538129091.9228122\r\n",
      "1526465956.28\t    1535465930.6480856\t1538129934.5156622\r\n",
      "1526466355.25\t    1535465997.850873\t1538130191.968829\r\n",
      "1526469077.69\t    1535471098.5022285\t1538130667.7495518\r\n",
      "1526472758.49\t    1535471589.6974597\t1538131442.5223112\r\n",
      "1526477452.11\t    1535489480.4087572\t1538132612.529224\r\n",
      "1526477591.25\t    1535495605.270843\t1538164315.796692\r\n",
      "1526477661.61\t    1535536595.4034352\t1538164516.4908414\r\n",
      "1526477719.31\t    1535536990.673935\t1538185014.7559695\r\n",
      "1526480574.63\t    1535537857.0108635\t1538188939.4692802\r\n",
      "1526480678.45\t    1535538026.0727892\t1538194765.8790808\r\n",
      "1526482840.12\t    1535538811.9921227\t1538225824.385981\r\n",
      "1526483333.78\t    1535538912.193693\t1538236198.5314517\r\n",
      "1526483605.46\t    1535539906.340315\t1538240803.5992877\r\n",
      "1526484183.97\t    1535541196.2753117\t1538246812.7872143\r\n",
      "1526551741.03\t    1535542313.1519787\t1538265125.1409142\r\n",
      "1526551764.27\t    1535543988.095752\t1538293959.7829702\r\n",
      "1526552581.68\t    1535547487.832742\t1538322508.6296325\r\n",
      "1526552647.8\t    1535547560.7416272\t1538333074.5223124\r\n",
      "1526552845.44\t    1535548082.4730258\t1538340279.960233\r\n",
      "1526565937.0\t    1535548830.4625525\t1538345780.2921503\r\n",
      "1526566003.79\t    1535548889.3227184\t1538355414.9699898\r\n",
      "1526581305.89\t    1535548979.028932\t1538371959.3982468\r\n",
      "1526581623.38\t    1535549029.9190307\t1538434519.3219302\r\n",
      "1526581950.39\t    1535549243.4158947\t1538434784.357337\r\n",
      "1526582541.47\t    1535549334.4345424\t1538435023.9462209\r\n",
      "1526582568.57\t    1535551198.0903852\t1538436212.0988266\r\n",
      "1526582598.44\t    1535551355.835628\t1538469925.870017\r\n",
      "1526582750.69\t    1535553667.1159968\t1538469976.790193\r\n",
      "1526583168.82\t    1535553950.344664\t1538482327.7697315\r\n",
      "1526583352.98\t    1535555423.7335875\t1538486124.7651565\r\n",
      "1526583469.92\t    1535555615.1876519\t1538486139.0374906\r\n",
      "1526583670.81\t    1535555898.6289165\t1538493371.543924\r\n",
      "1526584439.79\t    1535555911.1422455\t1538493759.7838058\r\n",
      "1526592362.99\t    1535556063.3234005\t1538493769.8080947\r\n",
      "1526593421.93\t    1535556227.0648859\t1538493778.208711\r\n",
      "1526593491.89\t    1535556671.770123\t1538493787.3565133\r\n",
      "1526593595.72\t    1535556679.0562513\t1538494994.1819072\r\n",
      "1526596439.23\t    1535556750.208118\t1538495798.0744123\r\n",
      "1526596652.93\t    1535560612.0345838\t1538500127.910895\r\n",
      "1526596761.84\t    1535561060.3457267\t1538504597.4488058\r\n",
      "1526682464.08\t    1535561176.2742155\t1538507862.4013004\r\n",
      "1526682544.58\t    1535561500.7616491\t1538510298.1498487\r\n",
      "1526682650.24\t    1535562063.2788658\t1538512005.2587183\r\n",
      "1526682722.87\t    1535650830.76152\t1538518712.1716878\r\n",
      "1526682862.11\t    1535651045.1123395\t1538525530.5382168\r\n",
      "1526682917.79\t    1535654741.2959347\t1538532758.3334758\r\n",
      "1526682951.96\t    1535668033.3801892\t1538534130.8271744\r\n",
      "1526851250.98\t    1535803037.0413225\t1538557713.4240477\r\n",
      "1526851331.54\t    1535809822.142208\t1538564860.206051\r\n",
      "1526851436.75\t    1535814354.6131754\t1538564887.473212\r\n",
      "1526855490.81\t    1535926170.1849298\t1538565036.8287272\r\n",
      "1527198335.3\t    1535926300.3994935\t1538565064.9590065\r\n",
      "1527231135.05\t    1535929704.5811777\t1538565282.4318538\r\n",
      "1527240070.67\t    1535930890.6068227\t1538565315.4097457\r\n",
      "1527285237.98\t    1535931860.6233199\t1538565440.0369294\r\n",
      "1527285288.89\t    1535974650.3976989\t1538565477.1507623\r\n",
      "1527285424.47\t    1535974741.5080812\t1538565596.5232463\r\n",
      "1527756892.66\t    1535974797.564611\t1538565639.0427878\r\n",
      "1527757224.51\t    1535974877.8116124\t1538565768.3665547\r\n",
      "1527757448.87\t    1535979126.19457\t1538565921.9654584\r\n",
      "1527758103.37\t    1535979366.5033998\t1538565975.5698895\r\n",
      "1527758374.33\t    1535979473.4216044\t1538566050.4629524\r\n",
      "1527758546.5\t    1535979629.8287947\t1538566109.7414978\r\n",
      "1527758839.07\t    1535979732.8721795\t1538566178.7258573\r\n",
      "1527758872.39\t    1535979778.1370432\t1538566188.5858674\r\n",
      "1527758935.72\t    1535979856.799495\t1538567025.2520785\r\n",
      "1527759079.7\t    1535979989.751829\t1538567093.931978\r\n",
      "1527759261.74\t    1535980187.1039531\t1538567677.5902562\r\n",
      "1527759548.38\t    1535980341.16636\t1538567746.5128229\r\n",
      "1527759581.79\t    1535980455.492443\t1538567894.3816566\r\n",
      "1527759653.82\t    1535980639.4226727\t1538567920.600816\r\n",
      "1527759856.17\t    1535980699.8494313\t1538569336.5730217\r\n",
      "1527760165.93\t    1535980814.1001694\t1538588234.620427\r\n",
      "1527760321.86\t    1535980934.9890287\t1538595700.8371303\r\n",
      "1527760391.92\t    1535981068.2847016\t1538603871.8361566\r\n",
      "1527760450.19\t    1535981345.3556135\t1538667900.80317\r\n",
      "1527760513.14\t    1535981537.8448381\t1538694640.3150272\r\n",
      "1527760550.71\t    1535981636.6700954\t1538724081.2519133\r\n",
      "1527760573.36\t    1535981807.1625597\t1538812293.5220706\r\n",
      "1527760787.9\t    1535982044.102192\t1538816334.9184852\r\n",
      "1527761063.58\t    1535984522.184706\t1538905682.924374\r\n",
      "1527761196.0\t    1535984547.7243843\t1538905812.5254009\r\n",
      "1527761249.8\t    1535984615.9307904\t1538906015.0058904\r\n",
      "1527761298.56\t    1535984797.292765\t1538939007.5919561\r\n",
      "1527761500.56\t    1535984873.0554912\t1538948769.77017\r\n",
      "1527761531.9\t    1535984925.5267231\t1539036279.515984\r\n",
      "1527761595.17\t    1535984989.1611538\t1539036304.0628145\r\n",
      "1527762048.63\t    1535985050.9816847\t1539036393.8169465\r\n",
      "1527762210.4\t    1535985326.2851148\t1539037402.4905627\r\n",
      "1527762223.37\t    1535985629.6560516\t1539038874.664594\r\n",
      "1527762288.1\t    1535991358.630128\t1539040368.6978405\r\n",
      "1527762318.08\t    1535991417.0198097\t1539047054.7221916\r\n",
      "1527762374.1\t    1535991451.1642578\t1539049653.773018\r\n",
      "1527762468.65\t    1535991467.1925077\t1539075572.3968208\r\n",
      "1527762649.38\t    1535991505.391402\t1539106383.863612\r\n",
      "1527762690.29\t    1535992297.2587376\t1539116112.2829292\r\n",
      "1527762775.51\t    1535993237.3294048\t1539116262.8048887\r\n",
      "1527778201.37\t    1535993512.2765718\t1539116964.1011162\r\n",
      "1527786877.97\t    1535993900.1275282\t1539117249.6413984\r\n",
      "1527795305.88\t    1535993994.669005\t1539120880.7742784\r\n",
      "1528058893.48\t    1535994212.3683453\t1539124183.6375942\r\n",
      "1528058975.4\t    1535994292.1445675\t1539129883.322546\r\n",
      "1528366403.42\t    1535994616.4867449\t1539166973.9067006\r\n",
      "1528366447.16\t    1535994648.694713\t1539174994.2483957\r\n",
      "1528366490.56\t    1535995106.3863328\t1539180127.8024476\r\n",
      "1528366565.49\t    1535995183.4444141\t1539180219.0338626\r\n",
      "1528366778.2\t    1535995318.309203\t1539180525.2784019\r\n",
      "1528366861.42\t    1536013141.2305672\t1539180620.3102045\r\n",
      "1528366888.76\t    1536013615.7338657\t1539180707.6324377\r\n",
      "1528410913.6\t    1536053141.9683616\t1539180798.7163227\r\n",
      "1529573117.84\t    1536053168.0113242\t1539180876.1067848\r\n",
      "1530007405.97\t    1536053235.0442278\t1539181063.6509585\r\n",
      "1530010504.9580996  1536053303.20586\t1539181725.772885\r\n",
      "1530010781.5245001  1536053349.016327\t1539184309.845018\r\n",
      "1530010956.0779471  1536053405.6495335\t1539206479.5996752\r\n",
      "1530011136.774148   1536053431.2790837\t1539206536.6263785\r\n",
      "1530011166.9447894  1536053716.3419971\t1539206989.098575\r\n",
      "1530011459.3724096  1536054011.1421895\t1539212116.4577\r\n",
      "1530011502.082099   1536054877.9944344\t1539212816.8502982\r\n",
      "1530011589.7031312  1536055052.1497111\t1539215513.2926977\r\n",
      "1530011692.8286767  1536055436.8578105\t1539225813.797767\r\n",
      "1530011845.8576438  1536055871.4256854\t1539243342.7108784\r\n",
      "1530011920.988832   1536055907.923039\t1539258162.4307227\r\n",
      "1530017949.9581003  1536056104.8569047\t1539264772.0339587\r\n",
      "1530022822.7810032  1536056412.9088154\t1539300395.1363854\r\n",
      "1530022853.3124514  1536060938.029548\t1539325850.72406\r\n",
      "1530023350.2328765  1536066711.362395\t1539355855.3869433\r\n",
      "1530023443.894873   1536066782.2346416\t1539361803.8221645\r\n",
      "1530023467.2084675  1536066926.798138\t1539369208.5706365\r\n",
      "1530023558.546619   1536071040.324174\t1539393810.9876993\r\n",
      "1530023714.6083171  1536102616.388236\t1539407892.840689\r\n",
      "1530027515.075548   1536102715.5702782\t1539428125.466498\r\n",
      "1530028306.017484   1536102853.543959\t1539466889.7781427\r\n",
      "1530915853.147268   1536145985.8178089\t1539479433.8300025\r\n",
      "1530998898.1377118  1536146003.412257\t1539492914.216426\r\n",
      "1531049680.8694208  1536162397.4862802\t1539602688.9712138\r\n",
      "1531049895.653839   1536176860.9220653\t1539608532.6916418\r\n",
      "1531049962.361975   1536176879.9617472\t1539616751.0156915\r\n",
      "1531049987.294126   1536176931.431985\t1539630775.5624497\r\n",
      "1531050008.3177896  1536176994.6990466\t1539713003.920049\r\n",
      "1531051073.44082    1536177044.2394514\t1539778769.198681\r\n",
      "1531051911.6644413  1536177083.0457182\t1539786707.1141675\r\n",
      "1531051970.1222346  1536179570.4081953\t1539826130.0951104\r\n",
      "1531052003.5745552  1536181790.2246525\t1539882339.1981676\r\n",
      "1531052121.1872714  1536185347.3765767\t1539882762.109654\r\n",
      "1531052151.9867392  1536219072.0498269\t1539883509.5709982\r\n",
      "1531052241.9448981  1536219276.8018456\t1539893236.6687295\r\n",
      "1531052280.1824682  1536219364.7988594\t1539907496.649787\r\n",
      "1531052306.6710641  1536219437.0233352\t1539917071.2467878\r\n",
      "1531052331.3883147  1536219537.201257\t1539950334.505475\r\n",
      "1531052382.5116727  1536219668.8048525\t1539956806.620774\r\n",
      "1531052408.3448014  1536271523.2824345\t1539981414.832749\r\n",
      "1531059130.5803926  1536296474.0260792\t1539993854.1682518\r\n",
      "1531059167.4514635  1536318238.043501\t1540021011.6494\r\n",
      "1531059218.1918793  1536318680.8526368\t1540061671.0077376\r\n",
      "1531059309.4646826  1536322787.0940626\t1540074925.4453595\r\n",
      "1531059471.2983916  1536322875.1637003\t1540088083.6697092\r\n",
      "1531059546.2968986  1536323008.7356412\t1540222585.0399923\r\n",
      "1531059588.3626518  1536324279.618861\t1540240859.3081377\r\n",
      "1531059646.2710328  1536324382.9641361\t1540242345.8579216\r\n",
      "1531059677.814003   1536324440.5452378\t1540242459.3513615\r\n",
      "1531059722.2397542  1536337606.178595\t1540245472.8163168\r\n",
      "1531059921.2347884  1536339012.3210018\t1540289385.459229\r\n",
      "1531059996.075477   1536570221.2173727\t1540290335.4611123\r\n",
      "1531060068.873961   1536570240.3895764\t1540290361.6358578\r\n",
      "1531060096.391836   1536594125.5074553\t1540290459.8792899\r\n",
      "1531060124.4566927  1536594198.6917372\t1540293928.9797447\r\n",
      "1531060995.6291704  1536594323.6472213\t1540295728.255049\r\n",
      "1531061154.6252973  1536594373.332669\t1540299833.3670335\r\n",
      "1531061236.0302124  1536594415.8153512\t1540312780.7227688\r\n",
      "1531061401.3567815  1536594472.1449902\t1540339383.6938522\r\n",
      "1531061570.198509   1536594485.207865\t1540371194.6924164\r\n",
      "1531061918.0115223  1536606683.001032\t1540390881.528168\r\n",
      "1531061966.0478945  1536607152.2170146\t1540390956.7841964\r\n",
      "1531061998.035741   1536607701.351258\t1540397544.8626406\r\n",
      "1531062064.81937    1536608781.6513479\t1540400560.5607505\r\n",
      "1531062077.26351    1536609641.3410447\t1540406037.6633174\r\n",
      "1531062181.8647883  1536609916.716956\t1540417610.039382\r\n",
      "1531062216.0765798  1536610044.462188\t1540446080.695604\r\n",
      "1531062246.9724026  1536610135.146256\t1540557395.3694391\r\n",
      "1531062377.1237674  1536610853.9292843\t1540559554.63038\r\n",
      "1531062992.6232262  1536611156.705085\t1540562023.5417354\r\n",
      "1531063030.0419333  1536611576.6805186\t1540567904.6928368\r\n",
      "1531063038.413407   1536613505.1886613\t1540769252.430431\r\n",
      "1531120826.0374873  1536613642.5320172\t1540811443.31866\r\n",
      "1531120846.1789672  1536614335.3454516\t1540816118.892748\r\n",
      "1531483842.5174022  1536614375.97771\t1540859496.5756078\r\n",
      "1531485749.5232718  1536614507.9414003\t1540893208.759251\r\n",
      "1531485782.3285296  1536615236.593678\t1540894451.991647\r\n",
      "1531486030.79683    1536615428.3734875\t1540894976.799893\r\n",
      "1531486086.3616269  1536615782.6034923\t2019-04-09T20:50:30.970685.zip\r\n",
      "1531486172.8379326  1536618324.018947\t2019-04-09T20:50:40.385462.zip\r\n",
      "1531487360.603819   1536618728.2881176\t2019-04-09T20:54:58.935662.zip\r\n",
      "1531489164.5019202  1536703958.545697\t2019-04-09T21:06:27.442871.zip\r\n",
      "1531489664.2175274  1536704474.2327678\t2019-04-09T21:06:41.915689.zip\r\n",
      "1531489789.8904064  1536704545.2266958\t2019-04-09T21:06:49.494329.zip\r\n",
      "1531489846.3864403  1536758551.9162195\t2019-04-09T21:07:11.979867.zip\r\n",
      "1531490060.632516   1536759099.5068324\t2019-04-09T21:10:13.634532.zip\r\n",
      "1531490188.3269186  1536759136.2576146\t2019-04-09T21:13:11.204891.zip\r\n",
      "1531490298.956448   1536759188.825195\t2019-04-09T21:13:34.645258.zip\r\n",
      "1531491554.5497625  1536759280.313265\t2019-04-09T21:14:05.977157.zip\r\n",
      "1531492027.7321994  1536759439.5950758\t2019-04-09T21:14:39.577088.zip\r\n",
      "1531492602.003927   1536759475.9476213\t2019-04-09T21:14:52.954641.zip\r\n",
      "1531492847.914331   1536761121.6236575\t2019-04-09T21:15:05.149140.zip\r\n",
      "1531492993.4826512  1536762242.9530241\t2019-04-09T21:15:19.744586.zip\r\n",
      "1531500788.420105   1536763215.6185393\t2019-04-09T21:15:31.933060.zip\r\n",
      "1531501062.7641594  1536763908.016718\t2019-04-09T21:15:58.614450.zip\r\n",
      "1531501083.0044131  1536764976.5244014\t2019-04-09T21:16:13.916131.zip\r\n",
      "1532438247.613542   1536783897.862042\t2019-04-09T21:16:57.159485.zip\r\n",
      "1532438272.7623441  1536792936.422717\t2019-04-09T21:17:26.006908.zip\r\n",
      "1532464270.9781072  1536793060.7236173\t2019-04-09T21:18:05.493865.zip\r\n",
      "1533042669.2012093  1536793448.7965384\t2019-04-09T21:18:48.247099.zip\r\n",
      "1533042703.1286578  1536794026.3496878\t2019-04-09T21:19:10.269327.zip\r\n",
      "1533050435.6535468  1536795047.5187545\t2019-04-09T21:19:29.515747.zip\r\n",
      "1533050567.6897445  1536816159.339693\t2019-04-09T21:19:57.580181.zip\r\n",
      "1533050657.2686498  1536817821.4470582\t2019-04-09T21:20:20.167442.zip\r\n",
      "1533050709.0726776  1536877872.631161\t2019-04-09T21:20:55.548662.zip\r\n",
      "1533051182.0878005  1536877935.8566775\t2019-04-09T21:21:23.803763.zip\r\n",
      "1533051226.0748837  1536917136.7022634\t2019-04-09T21:22:18.591711.zip\r\n",
      "1533051443.0726316  1536917601.4476233\t2019-04-09T21:25:04.404190.zip\r\n",
      "1533051531.8797684  1536918277.4340594\t2019-04-09T21:25:30.219077.zip\r\n",
      "1533051576.8224783  1536918580.1239316\t2019-04-09T21:25:54.378462.zip\r\n",
      "1533051622.553886   1536919263.2338135\t2019-04-09T21:37:07.381200.zip\r\n",
      "1533064108.4257424  1536919332.928802\t2019-04-09T21:41:11.826990.zip\r\n",
      "1533065158.5149446  1536919363.918844\t2019-04-09T21:41:38.862927.zip\r\n",
      "1533076150.1685324  1536919946.9646845\t2019-04-09T21:42:02.770732.zip\r\n",
      "1533076185.7815957  1536929335.0631092\t2019-04-09T21:42:27.597483.zip\r\n",
      "1533115206.991342   1536929357.010507\t2019-04-09T21:43:02.129717.zip\r\n",
      "1533115329.982769   1536937356.2821412\t2019-04-09T21:43:49.011869.zip\r\n",
      "1533115378.4692323  1536937465.6105824\t2019-04-09T21:44:28.902789.zip\r\n",
      "1533115412.9731092  1536937484.017383\t2019-04-09T21:45:10.006902.zip\r\n",
      "1533115523.7041311  1536937893.5399382\t2019-04-09T21:45:39.084990.zip\r\n",
      "1533115556.8538463  1536938308.1236534\t2019-04-09T21:46:15.656545.zip\r\n",
      "1533115759.703914   1536968869.0731943\t2019-04-09T21:46:56.388651.zip\r\n",
      "1533115794.255953   1536969870.537176\t2019-04-09T21:47:20.426464.zip\r\n",
      "1533115811.0536816  1537054813.0750446\t2019-04-09T21:47:46.508142.zip\r\n",
      "1533115888.964245   1537106312.1958551\t2019-04-09T21:48:42.528070.zip\r\n",
      "1533115926.8748076  1537106362.9557734\t2019-04-09T21:53:23.708674.zip\r\n",
      "1533115964.3709748  1537108637.0618434\t2019-04-09T21:54:53.724997.zip\r\n",
      "1533116022.0709941  1537111133.7303548\t2019-04-09T21:55:21.518633.zip\r\n",
      "1533116068.8030396  1537114068.0063732\t2019-04-09T22:34:18.169094.zip\r\n",
      "1533116331.0593247  1537185732.3398147\t2019-04-09T22:38:32.978752.zip\r\n",
      "1533116397.0677407  1537189800.962288\t2019-04-09T22:43:04.199023.zip\r\n",
      "1533135619.3021693  1537191587.7167857\t2019-04-09T22:48:56.555660.zip\r\n",
      "1533135736.7972734  1537201509.0480494\t2019-04-09T22:53:37.216036.zip\r\n",
      "1533135881.3451188  1537211008.570576\t2019-04-09T23:03:15.091588.zip\r\n",
      "1533135934.8154628  1537212958.5226936\t2019-04-09T23:09:52.904729.zip\r\n",
      "1533135956.8475535  1537217891.533092\t2019-04-09T23:23:37.483542.zip\r\n",
      "1533136021.1372654  1537218775.435846\t2019-04-10T00:11:47.881847.zip\r\n",
      "1533147925.5982656  1537281773.802932\t2019-04-10T00:33:44.945467.zip\r\n",
      "1533148554.9517753  1537315109.8307316\t2019-04-10T00:57:36.055262.zip\r\n",
      "1533148630.2036464  1537352269.0187693\t2019-04-10T01:33:19.317304.zip\r\n",
      "1533148778.29191    1537353746.1718214\t2019-04-10T01:57:28.847001.zip\r\n",
      "1533148807.577352   1537740902.3041158\t2019-04-10T03:39:39.578547.zip\r\n",
      "1534496463.1960952  1537740975.1807349\t2019-04-10T04:40:42.193657.zip\r\n",
      "1534509866.922161   1537741024.5474703\t2019-04-10T07:38:45.516771.zip\r\n",
      "1534509898.097091   1537741152.3995192\t2019-04-10T09:23:58.233510.zip\r\n",
      "1534511980.3169777  1537741572.84048\t2019-04-10T13:21:23.134949.zip\r\n",
      "1534512553.8040473  1537778903.1523595\t2019-04-10T13:43:15.915094.zip\r\n",
      "1534516109.0504766  1537781113.309172\t2019-04-10T14:10:15.614233.zip\r\n",
      "1534772583.5428824  1537781920.3581884\t2019-04-10T14:57:52.403388.zip\r\n",
      "1534772653.2084985  1537782043.4270532\t2019-04-10T15:20:19.443593.zip\r\n",
      "1534772712.4718304  1537782068.0192544\t2019-04-10T17:28:04.006670.zip\r\n",
      "1534772745.2105732  1537782082.3011024\t2019-04-10T19:58:23.811349.zip\r\n",
      "1534776904.7363808  1537782147.4425058\t2019-04-10T23:55:30.450413.zip\r\n",
      "1534778156.4387677  1537782148.8507273\t2019-04-11T02:14:55.245116.zip\r\n",
      "1534782810.0555325  1537785206.7184072\t2019-04-11T04:37:21.520666.zip\r\n",
      "1534787277.9960005  1537786365.968014\t2019-04-11T07:45:04.553332.zip\r\n",
      "1534857155.9524946  1537787075.3545656\t2019-04-11T09:11:29.368621.zip\r\n",
      "1534867087.6199315  1537803899.8457959\t2019-04-11T14:19:02.586472.zip\r\n",
      "1534867120.4230812  1537804310.222067\t2019-04-11T17:21:20.211222.zip\r\n",
      "1534867200.388434   1537813452.7381155\t2019-04-12T03:52:07.386353.zip\r\n",
      "1534869121.399549   1537813541.7005184\t2019-04-12T17:22:22.178988.zip\r\n",
      "1534869161.1926382  1537813587.6773067\t2019-04-13T07:19:54.394461.zip\r\n",
      "1534869185.928255   1537814188.5050097\t2019-04-13T18:30:21.050186.zip\r\n",
      "1534869284.5737307  1537814234.736365\t2019-04-13T20:32:18.263061.zip\r\n",
      "1534869348.8636909  1537814373.3932765\t2019-04-13T23:28:48.388411.zip\r\n",
      "1534869403.5099788  1537814593.3989975\t2019-04-14T02:39:39.666024.zip\r\n",
      "1534869459.223981   1537814695.9901\t2019-04-14T04:15:13.898510.zip\r\n",
      "1534869469.3682346  1537815163.614255\t2019-04-14T09:56:14.397895.zip\r\n",
      "1534869488.0396667  1537815378.6382942\t2019-04-14T12:58:40.398901.zip\r\n",
      "1534869581.5829365  1537818875.370365\t2019-04-15T02:49:27.243222.zip\r\n",
      "1534869684.6262617  1537819735.8832796\t2019-04-15T14:13:01.121798.zip\r\n",
      "1534889149.860666   1537825875.846802\t2019-04-16T04:38:40.812970.zip\r\n",
      "1535110411.3359396  1537825931.120817\t2019-04-16T15:34:41.940572.zip\r\n",
      "1535110473.4680054  1537825934.2977765\t2019-04-16T17:17:53.561803.zip\r\n",
      "1535110650.5673833  1537826071.6206954\t2019-04-16T19:27:50.762884.zip\r\n",
      "1535110980.9285934  1537826110.9903538\t2019-04-16T22:41:28.735783.zip\r\n",
      "1535319733.5699031  1537826294.1599042\t2019-04-17T00:50:08.300275.zip\r\n",
      "1535328798.5853965  1537826310.7652345\t2019-04-17T07:45:17.546509.zip\r\n",
      "1535361688.2723923  1537826347.8215792\t2019-04-17T11:02:35.888891.zip\r\n",
      "1535363614.7250953  1537827005.2722113\t2019-04-19T12:42:18.086862.zip\r\n",
      "1535363632.0241632  1537827038.1131938\t2019-04-19T22:04:07.676811.zip\r\n",
      "1535363661.2511797  1537836825.7048893\t2019-04-20T08:46:00.946958.zip\r\n",
      "1535363777.6958673  1537887015.4479425\t2019-04-24T09:31:48.072514.zip\r\n",
      "1535363794.2212117  1537887024.274855\t2019-04-24T11:45:11.796815.zip\r\n",
      "1535363823.4567902  1537887030.455758\t2019-04-24T13:42:57.244377.zip\r\n",
      "1535363865.004179   1537887106.7885256\t2019-04-24T16:34:24.411911.zip\r\n",
      "1535365214.6561465  1537887132.537864\t2019-04-24T18:20:18.452922.zip\r\n",
      "1535365275.4098215  1537887147.7473223\t2019-04-25T00:15:41.818333.zip\r\n",
      "1535365426.422141   1537890026.4763827\t2019-04-25T14:06:24.551510.zip\r\n",
      "1535371739.3152444  1537890033.7456837\t2019-04-29T16:33:27.679110.zip\r\n",
      "1535372951.9803913  1537890134.594067\t2019-04-30T07:04:49.491253.zip\r\n",
      "1535373874.0182154  1537890291.894352\t2019-04-30T10:27:21.098302.zip\r\n",
      "1535373905.50673    1537890351.064856\t2019-04-30T16:46:45.266207.zip\r\n",
      "1535374258.1329892  1537891958.0193906\t2019-05-01T07:49:11.753883.zip\r\n",
      "1535374270.584734   1537892153.3024216\t2019-05-01T19:30:12.053665.zip\r\n",
      "1535374345.2030206  1537892174.7894332\t2019-05-02T07:02:58.514532.zip\r\n",
      "1535374555.0360515  1537892195.683313\t2019-05-02T09:48:38.104070.zip\r\n",
      "1535374770.6381438  1537892220.609998\t2019-05-03T02:50:55.736759.zip\r\n",
      "1535377160.957973   1537892248.892299\t2019-05-03T06:56:10.453267.zip\r\n",
      "1535379472.0907457  1537892470.2327273\tlstm1\r\n",
      "1535379638.5517025  1537892481.0369792\truns\r\n",
      "1535380935.9877665  1537892487.8121188\twav_data\r\n",
      "1535381215.1703675  1537892497.1917565\r\n",
      "1535383381.4506273  1537892509.5616539\r\n"
     ]
    }
   ],
   "source": [
    "!ls runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: fast, MSE: 1.5415689945220947 +- 0.19128254055976868, MAE: 1.1227800846099854 +- 0.21494276821613312, PESQ: 2.809725 +- 0.6685985524774938, LSD: 6.567716657055897 +- 1.271925804419418\n"
     ]
    }
   ],
   "source": [
    "import sear_lib\n",
    "\n",
    "model = sear_lib.ModelInstance.load(\"runs/2019-05-03T06:56:10.453267.zip\")\n",
    "model.name = \"fast\"\n",
    "eval_task = Evaluation(model)\n",
    "evaluation = eval_task.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
