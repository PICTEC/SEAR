{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:265: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bernoulli.py:169: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "#path = os.path.realpath(os.path.join(os.getcwd(), \"..\"))\n",
    "path = \"/home/zantyr/Denoising\"\n",
    "sys.path.append(path)\n",
    "os.chdir(path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.io.wavfile as sio\n",
    "import tempfile\n",
    "\n",
    "from IPython.display import Image, Audio, display\n",
    "\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers         import Dropout, Input, Conv1D, Conv2D, AveragePooling2D, Flatten, Dense, Deconv2D, UpSampling2D, concatenate, BatchNormalization, Lambda, LeakyReLU, TimeDistributed, Reshape, LSTM, GaussianNoise\n",
    "from keras.models         import Model\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.utils          import to_categorical\n",
    "from keras.initializers   import Orthogonal\n",
    "from keras.regularizers   import L1L2, l2\n",
    "from keras.callbacks      import Callback\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import loaders\n",
    "from loaders.transform import AddGaussianNoise, Windowing, GSMize, MixReverb, MixNoise, ConstantQTransform, Transcript, LengthOfWindow, Length, Lengthen, Null, DivisiblePad\n",
    "from loaders.dataset import Dataset, enable_multiprocessing, disable_multiprocessing\n",
    "from loaders.feature import NormalizedLogPowerRFFT, Trim\n",
    "from loaders.experiment import SingleExperiment\n",
    "from loaders.measures import MSE\n",
    "from loaders.schedule import Schedule\n",
    "from loaders.estimator import DefaultVisualizeTransform, Estimator\n",
    "from loaders.extras import LossHistory, set_device, delog_griffin_lim, get_stft\n",
    "from loaders.custom import identity_loss\n",
    "set_device()               # switches to CPU if GPU busy\n",
    "enable_multiprocessing()   # for faster preprocessing of data (multicore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "TRAIN = 9000\n",
    "VALID = 80\n",
    "TEST = 80\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as sio\n",
    "import gc\n",
    "\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "tempnam = tempfile.mktemp\n",
    "\n",
    "log_fft_source = log_fft_target = phase = train = test = valid = experiment = None\n",
    "gc.collect()\n",
    "\n",
    "dataset = Dataset.from_folder(\"DAE-libri\",\n",
    "                              verbose = False,\n",
    "                              dataset_pad = 8,\n",
    "                              trim_lengths = 160000,\n",
    "                              cache = \"cache\",\n",
    "                              ram_cache_size = None,\n",
    "                              filter=lambda x:x.endswith(\".wav\") and not x.endswith(\".gsm.wav\"))\n",
    "\n",
    "\n",
    "log_fft_source = np.zeros([TEST, 1248, 129], np.float32)\n",
    "log_fft_target = np.zeros([TEST, 1248, 257], np.float32)\n",
    "phase = np.zeros([TEST, 1248, 129], np.float32)\n",
    "\n",
    "for ix, file in enumerate(dataset.files[TRAIN + VALID:TRAIN + VALID + TEST]):\n",
    "    print(ix)\n",
    "    data = sio.read(dataset.root + \"/\" + file)[1] # .astype(np.float32) to generate noise in the experiment...\n",
    "    oldname = tempnam() + '.oldwav'\n",
    "    sio.write(oldname, 16000, data)\n",
    "    tmpname = tempnam() + '.amr-nb'\n",
    "    newname = dataset.root + \"/\" + file + \".gsm.wav\"\n",
    "    subprocess.Popen(['sox', oldname, '-C', '7', '-r', '8000', tmpname]).communicate()\n",
    "    subprocess.Popen(['sox', tmpname, '-r', '16000', \"-e\", \"signed\", '-b', '16',  newname]).communicate()\n",
    "    list(map(os.remove, [oldname, tmpname]))\n",
    "\n",
    "\n",
    "window = np.hamming(512)\n",
    "for ix, file in enumerate(dataset.files[TRAIN + VALID:TRAIN + VALID + TEST]):\n",
    "    print(ix)\n",
    "    r = sio.read(dataset.root + \"/\" + file)[1].astype(np.float32)\n",
    "    r /= 2**15\n",
    "    for time in range(1248):\n",
    "        win = r[128 * time : 128 * time + 512]\n",
    "        if len(win) != 512:\n",
    "            break\n",
    "        fft = np.fft.rfft(window * win) / 512\n",
    "        log_fft_target[ix, time, :] = -np.log(np.abs(fft) ** 2 + 2e-12)\n",
    "    r = sio.read(dataset.root + \"/\" + file + \".gsm.wav\")[1].astype(np.float32)\n",
    "    r /= 2**15\n",
    "    for time in range(1248):\n",
    "        win = r[128 * time : 128 * time + 512]\n",
    "        if len(win) != 512:\n",
    "            break\n",
    "        fft = np.fft.rfft(window * win) / 512\n",
    "        log_fft_source[ix, time, :] = -np.log(np.abs(fft) ** 2 + 2e-12)[:129]\n",
    "        phase[ix, time, :] = np.angle(fft)[:129]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 4.188281\n"
     ]
    }
   ],
   "source": [
    "MEAN = 0 # min([log_fft_source.min(), log_fft_target.min()])\n",
    "# mean = log_fft_source.mean()\n",
    "#log_fft_source -= MEAN\n",
    "#log_fft_target -= MEAN\n",
    "# STD = []\n",
    "# for i in range(log_fft_source.shape[0]):\n",
    "#     rec = (log_fft_source[i] - mean) ** 2\n",
    "#     STD.append(rec.mean())\n",
    "# STD = np.sqrt(np.array(STD).mean())\n",
    "STD = log_fft_source.max() / 4.188281\n",
    "\n",
    "log_fft_source /= STD\n",
    "log_fft_target /= STD\n",
    "print(log_fft_source.min(), log_fft_source.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = log_fft_source[:,:,:129], log_fft_target[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/test_data.bin\", \"wb\") as f:\n",
    "    pickle.dump((test, phase), f)\n",
    "    \n",
    "with open(\"/tmp/data_norm.bin\", \"wb\") as f:\n",
    "    pickle.dump((MEAN, STD), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to normalize\n",
    "\n",
    "\"\"\"\n",
    "Check how it differentiates with normalization\n",
    "How does signal differentiates by normalization?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
